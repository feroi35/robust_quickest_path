# TODO et Carnet de bord


## TODO

- Faire les outils graphiques. Nombre d'instances résolues par rapport au temps de résolution
- creuser pourquoi CPLEX trouve autant de symmétries dans la résolution dualized
- coder les plans coupants
- réfléchir et implémenter une heuristique

- si la solution n'est pas valide (contrainte robuste), faire renvoyer 1,000,000 en score ? Ajouter une colonne "admissibilité"?

- Est-ce que ça vaut le coup de mettre des >= à la place des = dans les contraintes ? 
Equivalence pour des x binaires, mais quid du relâché? A tester

- Dans la résolution par dualisation, si l'on ne tourne pas assez longtemps et que l'on n'arrive pas à l'optimal, la solutoin que renvoie l'algorithme n'est pas forcément la même que le vrai score robuste. On garde la solution courante mais on recalcule le vrai score et on fait attention à ce que la solution soit bien admissible. 

- Factoriser le code: classe mère Method
avec une fonction virtuelle = 0 qui résout le problème qui sera définit dans les classes filles
Permet de standardiser le renvoi. 

- warm start à l'aide de l'heuristique? Dans dualized et plans coupants, solution réalisable qui permet de couper des branches plus vite et accélerer la résolution


## 04.01

Certaines instances crashent lors de la résolution statique: 

Quelques examples:

Running file: data/processed/1200_USA-road-d.COL.gr
Concert exception caught: CPLEX Error  1217: No solution exists.

Running file: data/processed/1500_USA-road-d.BAY.gr
Concert exception caught: CPLEX Error  1217: No solution exists.

Running file: data/processed/1500_USA-road-d.NY.gr
Concert exception caught: CPLEX Error  1217: No solution exists.

## 06.01

Pas de crash. Pas de solution existe car CPLEX n'avait pas eu le temps d'en trouver une.
Si on laisse tourner + de 10s, ça va.
Fixer une limite max de temps, 1 minute ?

## 17.01

Sur certaines grosses instances: linux kills le programme avec la méthode dualisée
Pas de message d'erreur, simplement : 
./run.sh: line 20:  2414 Killed                  ./myprogram "$file" "$method" "$verbose"

Mais si on creuse en affichant **dmesg**, on obtient:
Out of memory: Killed process 2576 (myprogram) total-vm:3771096kB, anon-rss:3110692kB, file-rss:4kB, shmem-rss:0kB, UID:1000 pgtables:6396kB oom_score_adj:0
Problème: c'est lorsqu'on utilise cplex que le programme meurt. Il arrive bien à se build avant...

https://www.ibm.com/support/pages/diagnosing-cplex-error-1001-out-memory
For some reason, cplex ne ressort pas l'erreur 1001, linux le tue avant
Contacter cplex ?

ulimit -a
max locked memory           (kbytes, -l) 65536
max memory size             (kbytes, -m) unlimited

max locked memory
The maximum size that may be locked into memory. Memory locking ensures the memory is always in RAM and never moved to the swap disk.

Quand on exporte le problème en .lp, on peut exécuter le model.lp depuis cplex lancé depuis Windows.
Donc lié à un problème de mémoire sur le WSL

Remarque: on obtient les warnings suivants:
Warning, line 1755417: Name 'x_0_0#235978' does not exist.

J'imagine que ce warning apparait pour toutes les variables qui sont "créées" mais jamais utilisées dans les contraintes ou l'objectif
c'est à dire, les variables qui représentent des arcs qui n'existent pas.

Dans mon fichier .wslconfig, 
j'avais memory = 4Gb
Quand j'enlève cette ligne, Cplex arrive à presolve le problème, ce qu'il ne faisait pas avant. Mais crash après trouver sa première solution

Out of memory: Killed process 1443 (myprogram) total-vm:3981856kB, anon-rss:3086536kB, file-rss:4kB, shmem-rss:0kB, UID:1000 pgtables:7136kB oom_score_adj:0

Essayons d'abord de modifier le problème pour que moins de mémoire soit prise. 
Pas besoin de stocker un vecteur de vecteurs entier remplis à moitié de NaN, il faut faire ça de manière intelligente.

- 1. Stocker un vecteur de vecteurs de vecteurs d'arc entrants et un vecteur de vecteurs d'arcs sortants. On stocke ainsi uniquement ce dont on a besoin.
- 2. (à tester) Virer env de la création de l'instance. C'est absurde comme manière de faire. De +, ça peut poser des problèmes lors de la résolution de sous-problèmes lors de l'algo des plans coupants. 

## 19.01

Résolution des sous-problèmes, c'est tellement overkill de résoudre le MILP
Si l'on trie au début les D et les poids des villes, il suffit de donner le plus gros coefficient aux premières villes/ aux premiers arcs. 

 data/processed/100_USA-road-d.COL.gr
 La contrainte robuste est plus faible que la contrainte statique (poids des villes additionné), pas possible. 
 A débugger. 
Faire attention aux décalages de 1. Indexation des instances commence à 1. Problème réglé.


En faisant tourner le modèle statique sur toutes les instances:

Running file: data/processed/2100_USA-road-d.COL.gr, 56 / 123
Advanced basis not built.
Advanced basis not built.

Running file: data/processed/2300_USA-road-d.COL.gr, 62 / 123
Advanced basis not built.
Concert exception caught: CPLEX Error  1217: No solution exists.
-> Simplement pas assez de temps donné, elle est énervée cette instance. Mais gestion des erreurs revues pour ne pas avoir d'incohérences comme cella là. 

## 21.01

Dans la version dualized avec les arcs, 
lambda était un BoolVarArray au lieu d'être un NumVarArray
-> corrigé

Problème de dualized.
Detecting symmetries...
Elapsed time for symmetry detection = 82.89 sec. (10000.42 ticks)
Found 2.310657e+347 symmetric permutations.

Comment est-ce qu'il peut détecter autant de symmétries ?
A creuser pour améliorer la résolution

Running file: data/processed/1000_USA-road-d.COL.gr, 2/123
Advanced basis not built.

Que signifie "Advanced basis not built" ?


## 23.01 r
error run_all dualized:
1800_COL, 2200_COL, 2200_NY, 2500_COL: mismatch robust_cost cplex_cost ; 
2100_NY: using missing arc;
2300_COL: advance basis not built + robust cost and cplex_cost mismatch;
2400_COL: no solution found;



## 24.01

Branch and cut: 
Problème: La résolution du sous problème de l'objectif robuste est + rapide avec CLEX qu'avec la résolution d'un knapsack continu (de 2 ordres de grandeur !!)
robust objective = 42766.5 time: 0.000247
robust objective bis = 42766.5, time: 0.010604

Le tri doit être lent? 
Non, time sort = 1.3e-05, négligeable

C'est bon, le temps de calcul avec CPLEX ne prenait en compte que la résolution alors que la construction du problème prend aussi beaucoup de temps. 
On a bien que la résolution gloutonne de notre knapsack continu est plus rapide. 

robust objective = 42766.5, time: 0.011856
robust objective bis = 42766.5, time: 0.00619

On perd beaucoup de temps à retrouver les arcs à partir de la solution. C'est la contrepartie de ne pas stocker toute la matrice de distance, ce qui faisait crasher WSL à cause de la mémoire. 

Mais on ne repart jamais de là quand on ajoute des coupes car on a directement les indexes des arcs utilisés. 
J'ai des coupes qui se passent bien. 
Puis à un moment, j'ai cette erreur 

free(): invalid next size (fast)

ILOLAZYCONSTRAINTCALLBACK4(myCallBack,IloBoolVarArray, x,
        IloBoolVarArray, y, IloNumVar, z, Instance, inst) {

    std::cout << "Callback called" << std::endl;
    IloEnv env = getEnv();

    unsigned int n_edges = getValue(IloSum(x));
    if (n_edges == 3) {
        std::cout << "n_edges = " << n_edges << std::endl;
    }
    std::vector<IloNum> weights(n_edges, 0.0); // d
    std::vector<IloNum> uncertainties(n_edges); // D
    std::vector<IloInt> idx_edges(n_edges);
    double static_score = 0.0;

    unsigned int count = 0;
    for (unsigned int a=0; a<inst.n_arc; a++) {
        if (getValue(x[a]) > 1e-3) {
            weights[count] = inst.mat[a].d;
            static_score += inst.mat[a].d;
            uncertainties[count] = inst.mat[a].D;
            idx_edges[count] = a;
            count++;
            std::cout << inst.mat[a].tail << " -> " << inst.mat[a].head << std::endl;
            std::cout << getValue(x[a]) << std::endl;
        }
    }
    if (count != n_edges) {
        std::cout << "Error: count = " << count << " != n_edges = " << n_edges << std::endl;
    }
    std::cout << "n_edges = " << n_edges << std::endl;
    std::cout << "weights = [";
    for (unsigned int i=0; i<n_edges; i++) {
        std::cout << weights[i] << " ";
    }
    std::cout << "]" << std::endl;
    std::cout << "uncertainties = [";
    for (unsigned int i=0; i<n_edges; i++) {
        std::cout << uncertainties[i] << " ";
    }
    std::cout << "]" << std::endl;
    std::cout << "idx_edges = [";
    for (unsigned int i=0; i<n_edges; i++) {
        std::cout << idx_edges[i] << " ";
    }
    std::cout << "]" << std::endl;

    std::vector<size_t> argsorted_weights = argsort(weights);
    double robust_attack = 0.0;
    double used_budget = 0.0;
    int idx = n_edges-1;
    IloExpr expr(env);
    while (used_budget < inst.d1 && idx >= 0) {
        unsigned int arc_idx = argsorted_weights[idx];
        float delta1_i = std::min(inst.d1 - used_budget, uncertainties[arc_idx]);
        used_budget += delta1_i;
        robust_attack += delta1_i * weights[arc_idx];

        IloInt real_arc = idx_edges[arc_idx];
        if (abs(weights[arc_idx] - inst.mat[real_arc].d) > 1e-3) {
            std::cout << "Error: weights[arc_idx] = " << weights[arc_idx] << " != inst.mat[real_arc].d = " << inst.mat[real_arc].d << std::endl;
            throw std::domain_error("Error in callBack");
        }
        expr += inst.mat[real_arc].d * delta1_i * x[real_arc];
        idx--;
    }
    std::cout << "used_budget = " << used_budget << std::endl;
    std::cout << "robust_attack = " << robust_attack << std::endl;
    std::cout << "static_score = " << static_score << std::endl;
    std::cout << "robust_score = " << static_score + robust_attack << std::endl;
    std::cout << "z = " << getValue(z) << std::endl;
    std::cout << expr << " <= z " << std::endl;
    std::cout << "\n\n\n" << std::endl;
    expr += IloScalProd(x, inst.d_vec);
    double robust_score = static_score + robust_attack;

    // Add the violated constraint
    if (robust_score > getValue(z) + 1e-3) {
        add(expr <= z);
    } else {
        std::cout << "No violated constraint found in callBack" << std::endl;
    }
    expr.end();
}

Pour l'instance 20_USA-road-d.BAY.gr
A un moment, on trouve que getValue(IloSum(x)) = 3 ie on utilise 3 arcs. 
Sauf que si l'on regarde tous les arcs utilisés ensuite, il y en a 4
CPLEX fait n'importe quoi

Et somehow, alors que weights est un vecteur de taille 3
Ca ne pose pas de problème d'écrire que weights[3] = ...

Il faudrait envoyer un message à CPLEX.

unsigned int a = getValue(IloSum(x))
# a = 3
IloInt b = getValue(IloSum(x));
# b = 3
float c = getValue(IloSum(x));
c = 4

C'est n'importe quoi. Je ne peux pas fixer la taille des vecteurs avant alors que ça fait gagner du temps parce que IloSum plante. 
Donc je vais faire des pushBack même si c'est moche, au moins ça marche


Ca marche, ça plie l'instance de taille 20. 
Mais ça prend 1 minute pour l'instance de taille 1000

Après profiling, toute la lenteur vient de cette boucle
std::vector<> xValues; 
for (unsigned int a = 0; a < inst.n_arc; a++) {
    xValues[a] = getValue(x[a]);
}
Cela prend tout le temps du callBack. 
Comment retrieve ces données sans perdre 40s par coupe?

https://www.ibm.com/docs/en/icos/22.1.1?topic=information-querying-solution-data
IloNumArray xValues(env);
getValues(xValues, x);

On passe de 40s à retrieve les données à 0.004 secondes pour une instance à 1000 noeuds
Si on laisse tourner 300s, on a 130 callBacks qui prennent 0.03s
Soit environ 5s. Donc le temps que prend notre callBack est négligeable devant celui de CPLEX pour optimiser
On peut laisser comme ça sans grapiller des secondes qui seront inutiles. 

Branch and cut ok, à lancer sur toutes les instances pour voir les résultats

Go plans sécants maintenant, il n'y a pas une différence énorme par rapport à ce qu'on vient de faire.

- Résolution des sous-problèmes, c'est tellement overkill de résoudre le MILP (RESOLU)
Si l'on trie au début les D et les poids des villes, il suffit de donner le plus gros coefficient aux premières villes/ aux premiers arcs. 
On va l'appeler en callback, donc c'est important que ce soit rapide. Appeler CPLEX, rien que l'interface, j'imagine que ça prend du temps alors que le problème est hyper simple à résoudre sans l'appeler. 

Pour cela, faire un tri lors de la création de l'instance.
Par ordre décroissant de D_vec[a] * d_vect[a] pour le score robuste
Par ordre décroissant de ph pour la contrainte robuste

Ensuite, il suffit de parcourir dans l'ordre les villes/arcs de la solution et remplir autant que possible les incertitudes

Remarque: plusieurs centaines de milliers d'arcs. Tri en n log n. Une solution courante a max 20 arcs. 
Donc on peut faire énormément de sous problèmes avant de rentabiliser le tri initial, qu'on ne fait donc pas. 

Plans coupants
Done mais prend des plombes de tout recommencer à chaque fois qu'on ajoute une contrainte
Quel est l'avantage de faire ça. Garder toutes les fonctionnalités CPLEX dont on se prive lorsqu'on ajoute des CallBacks ? 

## 25.01

Ca pourrait être utile pour faire des statistiques de savoir **quand a été trouvée la meilleure solution par CPLEX**
Souvent très rapide et ensuite CPLEX passe son temps à essayer de réduire le gap jusqu'à prouver l'optimalité.

C'est possible de faire cela, mais uniquement avec des CallBack et ça désactive des fonctionnalités de CPLEX. 
Pas de solution miracle après recherche. Donc on va s'asseoir sur ces stats. 

## 25.01 r
heuristique fonctionne très rapidement (environ 1s) pour la plupart des instances.
certains cas pathologique: 1300_BAY arrive pas a trouver une solution réalisable au début avec un dijkstra. a priori pas adapté aux petites instances.
Pour les cas qui fonctionnent, la "borne_inf" semble bien etre une borne inf, mais aucune certitude -> est ce que on peut le prouver?
Il faudrait regarder comment injecter la solution de l'heuristique dans un B&B et voir l'impact sur les performances.
La borne inf en est une si la contrainte robuste est contraignante: si on est laregment bon, on va etre ok pour K=0 et donc c'est pas pertinent


